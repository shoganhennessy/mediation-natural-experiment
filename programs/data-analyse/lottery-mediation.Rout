
R version 4.5.1 (2025-06-13) -- "Great Square Root"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #!/usr/bin/R
> ## Senan Hogan-Hennessy, 11 July 2025.
> ## Script to to extract relevant data from Oregon Health Insurance rep package.
> print(Sys.time())
[1] "2025-09-27 15:41:51 EDT"
> set.seed(47)
> 
> ## Packages:
> # functions for data manipulation and visualisation
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.2     ✔ tibble    3.2.1
✔ lubridate 1.9.4     ✔ tidyr     1.3.1
✔ purrr     1.0.4     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> # Functions for bootstrapping.
> library(boot)
> library(fixest)
> # Package forsemi-parametric CF by splines.
> library(mgcv)
Loading required package: nlme

Attaching package: ‘nlme’

The following object is masked from ‘package:dplyr’:

    collapse

This is mgcv 1.9-1. For overview type 'help("mgcv-package")'.
> library(splines)
> # Library for better colour choice.
> library(ggthemes)
> # Library for equations in plots
> library(latex2exp)
> # Package for LaTeX tables
> library(xtable)
> 
> 
> # Define folder paths (1) input data (2) clean data.
> data.folder <- file.path("..", "..", "data", "oregon-lottery-icspr")
> figures.folder <- file.path("..", "..", "text", "sections", "figures")
> tables.folder <- file.path("..", "..", "text", "sections", "tables")
> presentation.folder <- file.path("..", "..", "presentation",
+     "presentation-files", "figures")
> # Size of figures.
> fig.width <- 15
> fig.height <- (2 / 3) * fig.width
> presentation.width <- 15
> presentation.height <- (7 / 12) * presentation.width
> # Number of digits to round to.
> digits.no <- 2
> # List of 3 default colours.
> colour.list <- c(
+     "#1f77b4", # Blue
+     "#2ca02c", # Green
+     "#d62728") # Red
> 
> 
> ################################################################################
> ## Load the Oregon Health Insurance Experiment replication data.
> 
> # Load the pre-cleaned Oregon Health data.
> analysis.data <- data.folder %>%
+     file.path("cleaned-oregon-data.csv") %>%
+     read_csv()
Rows: 11126 Columns: 17
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (17): lottery_iv, hh_size, any_insurance, any_healthcare, usual_health_l...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> 
> # Factorise the relevant variables.
> analysis.data$hh_size <- factor(analysis.data$hh_size)
> analysis.data$usual_health_location <- factor(
+     analysis.data$usual_health_location)
> 
> 
> ################################################################################
> ## Define the functions to use.
> 
> # Estimate the values, given a first and second-stages
> estimated.values <- function(firststage.reg, secondstage.reg, totaleffect.reg,
+     data, complier.adjustment = NULL){
+     ### Inputs:
+     ## data, a data frame simulated from above.
+     input_Z0.data <- data
+     input_Z1.data <- data
+     input_D0.data <- data
+     input_D1.data <- data
+     input_Z0.data$Z <- 0
+     input_Z1.data$Z <- 1
+     input_D0.data$D <- 0
+     input_D1.data$D <- 1
+     # calculate the first-stage by prediction
+     firststage.est <- predict(
+         firststage.reg, newdata = input_Z1.data, type = "response") - predict(
+             firststage.reg, newdata = input_Z0.data, type = "response")
+     # Calculate the total effect estimate by prediction.
+     totaleffect.est <- predict(
+         totaleffect.reg, newdata = input_Z1.data) - predict(
+             totaleffect.reg, newdata = input_Z0.data)
+     # calculate the second-stage direct effect
+     direct.est <- predict(
+         secondstage.reg, newdata = input_Z1.data) - predict(
+             secondstage.reg, newdata = input_Z0.data)
+     # calculate the second-stage (controlled) indirect effect
+     indirect.est <- predict(
+         secondstage.reg, newdata = input_D1.data) - predict(
+             secondstage.reg, newdata = input_D0.data)
+     # Add the Kline Walters (2019) IV-type complier adjustment (provided externally).
+     if (!is.null(complier.adjustment)) {
+         indirect.est <- indirect.est + complier.adjustment
+     }
+     # Return the mean estimates.
+     output.list <- list(
+         "first-stage"     = mean(firststage.est, na.rm = TRUE),
+         "total-effect"    = mean(totaleffect.est, na.rm = TRUE),
+         "direct-effect"   = mean(direct.est, na.rm = TRUE),
+         "indirect-effect" = mean(firststage.est * indirect.est, na.rm = TRUE))
+     # Return the output.list
+     return(output.list)
+ }
> 
> # Define a function to Heckman selection correct mediation est, in two-stages.
> mediate.unadjusted <- function(Y, Z, D, X_iv, data,
+     X_minus = NULL, control_iv = NULL, indices = NULL){
+     # Bootstrap sample, if indices provided.
+     if (!is.null(indices)){
+         data <- data[indices, ]
+     }
+     # Make the names consistent
+     data$Y <- data[[Y]]
+     data$Z <- data[[Z]]
+     data$D <- data[[D]]
+     total.formula <- formula(paste0("Y ~ 1 + Z + ", X_minus))
+     firststage.formula <- formula(paste0("D ~ 1 + Z * (", X_iv, ") +", X_minus))
+     secondstage.formula <- formula(paste0("Y ~ 1 + Z * D + ", X_minus))
+     # Start counting coefficients estimated.
+     count.coef <- 0
+     # 0. Total effect regression.
+     totaleffect.reg <- lm(total.formula, data = data)
+     count.coef <- count.coef + length(totaleffect.reg$coefficients)
+     # 1. Regular first-stage (well identified).
+     firststage.reg <- lm(firststage.formula, data = data)
+     count.coef <- count.coef + length(firststage.reg$coefficients)
+     # 2. Estimate second-stage (naive case has no CFs).
+     unadjusted_secondstage.reg <- lm(secondstage.formula, data = data)
+     count.coef <- count.coef + length(unadjusted_secondstage.reg$coefficients)
+     # Compile the estimates.
+     unadjusted.est <- estimated.values(
+         firststage.reg, unadjusted_secondstage.reg,
+         totaleffect.reg, data,
+         complier.adjustment = NULL)
+     # Return the off-setting estimates.
+     output.list <- c(
+         unadjusted.est$"first-stage",
+         unadjusted.est$"total-effect",
+         unadjusted.est$"direct-effect",
+         unadjusted.est$"indirect-effect",
+         count.coef)
+     return(output.list)
+ }
> 
> #! Test it out, with the specification I want.
> mediate.est <- mediate.unadjusted(
+     Y = "Y_health", Z = "lottery_iv", D = "any_insurance",
+     X_iv = "usual_health_location",
+     X_minus = paste0("hh_size + dia_diagnosis +",
+         "ast_diagnosis + hbp_diagnosis + emp_diagnosis + ami_diagnosis +",
+         "chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis"),
+     analysis.data)# %>% sample_frac(prop = 1, replace = TRUE))
> print(mediate.est)
[1]  0.18410960  0.05271893  0.03620666  0.01362546 53.00000000
> 
> # Define a function to Heckman selection correct mediation est, in two-stages.
> lambda_1.fun <- function(pi.est){
+         # Inv Mills ratio, taking as input the estimated mediator propensity.
+         return(dnorm(qnorm(pi.est)) / pnorm(qnorm(pi.est)))
+     }
> # THe actual function.
> mediate.heckit <- function(Y, Z, D, X_iv, data,
+     X_minus = NULL, indices = NULL){
+     # Bootstrap sample, if indices provided.
+     if (!is.null(indices)){
+         data <- data[indices, ]
+     }
+     # Make the names consistent
+     data$Y <- data[[Y]]
+     data$Z <- data[[Z]]
+     data$D <- data[[D]]
+     total.formula <- formula(paste0("Y ~ 1 + Z + ", X_minus))
+     firststage.formula <- formula(paste0("D ~ 1 + Z * (", X_iv, ") +", X_minus))
+     secondstage.formula <- formula(paste0("Y ~ 1 + Z * D + ", X_minus,
+         " + lambda_0 + lambda_1"))
+     # Start counting coefficients estimated.
+     count.coef <- 0
+     # 0. Total effect regression.
+     totaleffect.reg <- lm(total.formula, data = data)
+     count.coef <- count.coef + length(totaleffect.reg$coefficients)
+     # 1. Probit first-stage (well identified).
+     heckit_firststage.reg <- glm(firststage.formula,
+         family = binomial(link = "probit"),
+         data = data)
+     count.coef <- count.coef + length(heckit_firststage.reg$coefficients)
+     # 2. Define the CFs --- for assumed N(0,1) dist.
+     pi.est <- predict(heckit_firststage.reg, type = "response")
+     data$lambda_0 <- (1 - data$D) * lambda_1.fun(pi.est) * (
+         - pi.est / (1 - pi.est))
+     data$lambda_1 <- data$D * lambda_1.fun(pi.est)
+     # 3. Estimate second-stage, including the CFs.
+     heckit_secondstage.reg <- lm(secondstage.formula, data = data)
+     count.coef <- count.coef + length(heckit_secondstage.reg$coefficients)
+     # Compensate complier difference in AIE, by Kline Walters (2019) IV-type adjustment.
+     input_Z0.data <- data
+     input_Z1.data <- data
+     input_Z0.data$Z <- 0
+     input_Z1.data$Z <- 1
+     pi_0.est <- predict(heckit_firststage.reg, newdata = input_Z0.data)
+     pi_1.est <- predict(heckit_firststage.reg, newdata = input_Z1.data)
+     Gamma.big <-  (pi_1.est * lambda_1.fun(pi_1.est)
+         - pi_0.est * lambda_1.fun(pi_0.est)) / (pi_1.est - pi_0.est)
+     rho_0 <- as.numeric(coef(heckit_secondstage.reg)["lambda_0"])
+     rho_1 <- as.numeric(coef(heckit_secondstage.reg)["lambda_1"])
+     complier.adjustment <- (rho_1 - rho_0) * Gamma.big
+     # Compile the estimates.
+     heckit.est <- estimated.values(
+         heckit_firststage.reg, heckit_secondstage.reg,
+         totaleffect.reg, data,
+         complier.adjustment = complier.adjustment)
+     # Return the off-setting estimates.
+     output.list <- c(
+         heckit.est$"first-stage",
+         heckit.est$"total-effect",
+         heckit.est$"direct-effect",
+         heckit.est$"indirect-effect",
+         count.coef)
+     return(output.list)
+ }
> 
> #! Test it out, with the specification I want.
> mediate.est <- mediate.heckit(
+     Y = "Y_health", Z = "lottery_iv", D = "any_healthcare",
+     X_iv = "usual_health_location",
+     X_minus = paste0("hh_size + dia_diagnosis +",
+         "ast_diagnosis + hbp_diagnosis + emp_diagnosis + ami_diagnosis +",
+         "chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis"),
+     data = analysis.data %>% sample_frac(prop = 1, replace = TRUE))
Warning messages:
1: In qnorm(pi.est) : NaNs produced
2: In qnorm(pi.est) : NaNs produced
3: In qnorm(pi.est) : NaNs produced
4: In qnorm(pi.est) : NaNs produced
> print(mediate.est)
[1]  0.04902046  0.04963009  0.02958301  0.01810015 55.00000000
> 
> # Define a function to two-stage semi-parametric CF for CM effects.
> mediate.semiparametric <- function(Y, Z, D, X_iv, data,
+     X_minus = NULL, indices = NULL){
+     # Bootstrap sample, if indices provided.
+     if (!is.null(indices)){
+         data <- data[indices, ]
+     }
+     # Make the names consistent
+     data$Y <- data[[Y]]
+     data$Z <- data[[Z]]
+     data$D <- data[[D]]
+     total.formula <- formula(paste0("Y ~ 1 + Z +", X_minus))
+     firststage.formula <- formula(paste0("D ~ 1 + Z * (", X_iv, ") +", X_minus))
+     secondstage.formula <- formula(paste0("Y ~ 1 + Z + ", X_minus,
+         " + s(pi.est, bs = 'cr')"))
+     # Get relevant columns for imputation.
+     input_Z0.data <- data
+     input_Z1.data <- data
+     input_D0.data <- data
+     input_D1.data <- data
+     input_Z0.data$Z <- 0
+     input_Z1.data$Z <- 1
+     input_D0.data$D <- 0
+     input_D1.data$D <- 1
+     # Start counting coefficients estimated.
+     count.coef <- 0
+     # 1. Total effect regression.
+     totaleffect.reg <- lm(total.formula, data = data)
+     totaleffect.est <- mean(predict(
+         totaleffect.reg, newdata = input_Z1.data) - predict(
+             totaleffect.reg, newdata = input_Z0.data))
+     count.coef <- count.coef + length(totaleffect.reg$coefficients)
+     # 2. Semi-parametric first-stage
+     cf_firststage.reg <- glm(firststage.formula,
+         family = binomial(link = "probit"),
+         data = data)
+     data$pi.est <- predict(cf_firststage.reg, type = "response")
+     pi_0.est <- predict(cf_firststage.reg, newdata = input_Z0.data, type = "response")
+     pi_1.est <- predict(cf_firststage.reg, newdata = input_Z1.data, type = "response")
+     pi.bar <- mean(pi_1.est - pi_0.est)
+     count.coef <- count.coef + length(cf_firststage.reg$coefficients)
+     # Calculate the levels of pi, accounting for few values in the IV.
+     distinct_cf.values <- min(
+         length(unique(data$pi.est)) - 2, as.integer(nrow(data) / 2000))
+     # 3. Semi-parametric series estimation of the second-stage.
+     cf_secondstage_D0.reg <- gam(secondstage.formula,
+         method = "REML", data = data, subset = (D == 0))
+     cf_secondstage_D1.reg <- gam(secondstage.formula,
+         method = "REML", data = data, subset = (D == 1))
+     count.coef <- count.coef + length(cf_secondstage_D0.reg$coefficients)
+     count.coef <- count.coef + length(cf_secondstage_D1.reg$coefficients)
+     # 4. Compose the CM effects from this object.
+     D_0 <- 1 - mean(data$D)
+     D_1 <- 1 - D_0
+     # 4.1 ADE point estimate, from the CF model.
+     gammma.est <- coef(cf_secondstage_D0.reg)["Z"]
+     delta_plus.est <- coef(cf_secondstage_D1.reg)["Z"]
+     ade.est <- as.numeric(D_0 * gammma.est + D_1 * delta_plus.est)
+     # 4.2 AIE by using ADE estimate, relative to ATE.
+     # (Avoiding semi-parametric extrapolation, see notes on ATE comparison)
+     delta.est <- delta_plus.est - gammma.est
+     ade_Z0.est <- gammma.est + delta.est * mean(
+         data$D[data$Z == 0])
+     ade_Z1.est <- gammma.est + delta.est * mean(
+         data$D[data$Z == 1])
+     aie.est <- (totaleffect.est - mean(
+         (1 - data$Z) * ade_Z1.est + (data$Z) * ade_Z0.est))
+     # Return the estimates.
+     output.list <- c(
+         pi.bar,
+         totaleffect.est,
+         ade.est,
+         aie.est,
+         count.coef)
+     return(output.list)
+ }
> 
> #! Test it out, with the specification I want.
> mediate.est <- mediate.semiparametric(
+     Y = "Y_health", Z = "lottery_iv", D = "any_healthcare",
+     X_iv = "usual_health_location",
+     X_minus = paste0("hh_size + dia_diagnosis +",
+         "ast_diagnosis + hbp_diagnosis + emp_diagnosis + ami_diagnosis +",
+         "chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis"),
+     data = analysis.data)# %>% sample_frac(prop = 1, replace = TRUE))
> print(mediate.est)
[1]  0.04172030  0.05271893  0.01818865  0.03453035 82.00000000
> 
> # Define a function to bootstrap.
> mediate.bootstrap <- function(Y, Z, D, X_iv, data,
+         X_minus = NULL, type = "parametric", boot.reps = 10){
+     # Define an empty data.frame.
+     boot.data <- data.frame(matrix(ncol = 4, nrow = 0))
+     names(boot.data) <- c(
+         "First-stage", "ATE", "ADE", "AIE")
+     j <- 1
+     for (i in 1:boot.reps){
+         if ((boot.reps >= 100) & ((100 * i / boot.reps) %% 5 == 0)){
+             cat(paste0(i, " out of ", boot.reps, ", ", 100 * (i / boot.reps),
+                 "% done.", "\n"))
+         }
+         boot.indices <- sample(1:nrow(data), nrow(data), replace = TRUE)
+         if (type == "parametric"){
+             point.est <- mediate.heckit(Y, Z, D, X_iv, data,
+                 X_minus = X_minus, indices = boot.indices)
+             }
+             else if (type == "semi-parametric"){
+                 point.est <- mediate.semiparametric(
+                     Y, Z, D, X_iv, data,
+                     X_minus = X_minus, indices = boot.indices)
+             }
+             else if (type == "unadjusted"){
+                 point.est <- mediate.unadjusted(Y, Z, D, X_iv, data,
+                     X_minus = X_minus, indices = boot.indices)
+             }
+             else {
+                 stop(paste0("The type option only takes values of ",
+                     'c("parametric", "semi-parametric", "unadjusted").'))
+             }
+         boot.data[i, ] <- point.est
+     }
+     return(boot.data)
+ }
> 
> #! Test it out.
> mediate.boot <- mediate.bootstrap(
+     Y = "Y_health", Z = "lottery_iv", D = "any_healthcare",
+     X_iv = "usual_health_location",
+     X_minus = paste0("hh_size + dia_diagnosis +",
+         "ast_diagnosis + hbp_diagnosis + emp_diagnosis + ami_diagnosis +",
+         "chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis"),
+     data = analysis.data, type = "unadjusted", boot.reps = 10)
Warning messages:
1: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
2: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
3: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
4: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
5: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
6: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
7: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
8: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
9: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
10: In matrix(value, n, p) :
  data length [5] is not a sub-multiple or multiple of the number of columns [4]
> print(mediate.boot)
   First-stage        ATE        ADE           AIE
1   0.01958526 0.06167365 0.06177846 -5.774485e-05
2   0.02186444 0.05457535 0.05486550 -1.759759e-04
3   0.04257869 0.05743405 0.05843391 -7.816477e-04
4   0.03492471 0.06478162 0.06620302 -9.549385e-04
5   0.05462943 0.05415838 0.05593743 -1.615635e-03
6   0.03479727 0.05577089 0.05630015 -4.223050e-04
7   0.02918130 0.06203869 0.06309734 -7.426826e-04
8   0.04293353 0.05515110 0.05554714 -2.924929e-04
9   0.04219358 0.06291833 0.06415576 -1.017365e-03
10  0.03888613 0.05647897 0.05814651 -1.358612e-03
> 
> ## Define a function to wrap around all the others.
> mediate.selection <- function(Y, Z, D, X_iv, X_minus, data,
+     type = "parametric", boot.reps = 10){
+     # Calculate the point estimates.
+     if (type == "parametric"){
+         point.est <- mediate.heckit(Y, Z, D, X_iv, data, X_minus = X_minus)
+     }
+     else if (type == "semi-parametric"){
+         point.est <- mediate.semiparametric(Y, Z, D, X_iv, data, X_minus = X_minus)
+     }
+     else if (type == "unadjusted"){
+         point.est <- mediate.unadjusted(Y, Z, D, X_iv, data, X_minus = X_minus)
+     }
+     else {
+         stop(paste0("The type option only takes values of ",
+             'c("parametric", "semi-parametric", "unadjusted").'))
+     }
+     count.coef <- point.est[5]
+     # Calculate the SEs by a non-parametric bootstrap.
+     if (!is.null(boot.reps)){
+         if (boot.reps < 500){
+             print(paste0("Attempting to bootstrap with fewer than 500 reps.",
+                 "  Are you sure?  This is likely not enough for convergence."))
+         }
+         point.boot <- mediate.bootstrap(
+             Y = Y, Z = Z, D = D, X_minus = X_minus, X_iv = X_iv,
+             data = data, type = type, boot.reps = boot.reps)
+     }
+     # Report output
+     point.est <- as.matrix(c(100 * point.est[1:4], point.est[4] / point.est[2]))
+     point.se <- as.matrix(c(
+         sd(100 * point.boot$"First-stage"),
+         sd(100 * point.boot$"ATE"),
+         sd(100 * point.boot$"ADE"),
+         sd(100 * point.boot$"AIE"),
+         sd(point.boot$"AIE" / point.boot$"ATE")))
+     tratio <- as.matrix(point.est / point.se)
+     ptratio <- as.matrix(2 * pt(abs(tratio),
+         df = nrow(data) - count.coef, lower.tail = FALSE))
+     # Preapred object to putput.
+     out <- list(
+         coefficients = point.est,
+         SE = point.se,
+         tratio = tratio,
+         ptratio = ptratio,
+         type = type,
+         variables = paste(Z, D, Y, sep = ", "),
+         boot.reps = boot.reps)
+     rownames(out$coefficients) <-
+         c("First-stage", "ATE", "ADE", "AIE", "Proportion, AIE / ATE")
+     rownames(out$SE)      <-rownames(out$coefficients)
+     rownames(out$tratio)  <-rownames(out$coefficients)
+     rownames(out$ptratio) <-rownames(out$coefficients)
+     class(out) <- "mediate.selection"
+     return(out)
+ }
> 
> # Print applied to the function.
> print.mediate.selection <- function(x, digits = 4, ...){
+     cat("Treatment, Mediator, Outcome: \n")
+     cat(x$variables)
+     cat("\n")
+     est <- cbind(x$coefficients, x$SE)
+     colnames(est) <- c("Coefficients", "SE")
+     cat(paste0("\n", x$type, " Estimates, With SEs from ", x$boot.reps, " bootstrap replications."))
+     cat("\n\n")
+     print.default(format(est, digits = digits), quote = FALSE)
+ }
> 
> # Apply the summary function, to get a presentable output.
> summary.mediate.selection <- function(object, ...){
+     TAP <- cbind(
+         Estimate = coef(object),
+         SE = object$SE,
+         ptratio = object$ptratio )
+     colnames(TAP) <- c("Estimate", "SE", "P")
+     res <- list(variables = object$variables, coefficients = TAP)  
+     class(res) <- "summary.larf"
+     return(res)
+ }
> 
> # Presentable summary, via printing.
> print.summary.mediate.selection <- function(x, digits = 4, ...){
+     cat("Treatment, Mediator, Outcome: \n")
+     cat(x$variables)
+     cat("\n")
+     print.default(round(x$coefficients, digits = digits), quote = FALSE)
+ }
> 
> 
> ################################################################################
> ## Show the regular location is a strong IV for healthcare visits.
> 
> # Note values in usual health location:
> usual_health_location.list <- c(
+     "1. Private clinic",
+     "2. Public clinic",
+     "3. Hospital clinic",
+     "4. Hospital A&E",
+     "5. Urgent care",
+     "6. Other clinic",
+     "7. No regular")
> 
> # Show that the health location influences healthcare take-up
> location.data <- analysis.data %>%
+     mutate(usual_health_location_name =
+         ifelse(usual_health_location == 1, usual_health_location.list[1],
+         ifelse(usual_health_location == 2, usual_health_location.list[2],
+         ifelse(usual_health_location == 3, usual_health_location.list[3],
+         ifelse(usual_health_location == 4, usual_health_location.list[4],
+         ifelse(usual_health_location == 5, usual_health_location.list[5],
+         ifelse(usual_health_location == 6, usual_health_location.list[6],
+         ifelse(usual_health_location == 7, usual_health_location.list[7],
+             "WARNING")))))))) %>%
+     group_by(usual_health_location_name) %>%
+     summarise(
+         any_healthcare_mean = mean(any_healthcare, na.rm = TRUE),
+         any_healthcare_sd = sd(any_healthcare, na.rm = TRUE),
+         count = n()) %>%
+     ungroup() %>%
+     mutate(any_healthcare_se = any_healthcare_sd / (count^(0.5)),
+         any_healthcare_mean_lower = any_healthcare_mean - 1.96 * any_healthcare_se,
+         any_healthcare_mean_upper = any_healthcare_mean + 1.96 * any_healthcare_se)
> 
> # Draw the horizontal bar chart
> location.plot <- location.data %>%
+     ggplot(aes(x = usual_health_location_name)) +
+     # Bars of the mean
+     geom_bar(aes(y = any_healthcare_mean, fill = usual_health_location_name),
+         colour = "black", stat = "identity") +
+     # Error bars
+     geom_errorbar(
+         aes(ymin = any_healthcare_mean_lower, ymax = any_healthcare_mean_upper),
+         width = 0.2, position = position_dodge(0.9)) +
+     # Make horizontal and format.
+     coord_flip() +
+     theme_bw() +
+     scale_x_discrete(name = "", limits = usual_health_location.list[7:1]) +
+     scale_y_continuous(expand = c(0, 0),
+         name = TeX(r"(Visited healthcare in following 12 months, $\Pr( \,D_i = 1 \, | \, X^{IV}_i \,)$)"),
+         limits = c(0, 1.025), oob = scales::rescale_none,
+         breaks = seq(0, 1, by = 0.1)) +
+     ggtitle("Usual Healthcare Location") +
+     theme(legend.position = "none",
+         axis.text.y = element_text(hjust = 0),
+         plot.title = element_text(hjust = 0, size = rel(1)),
+         plot.title.position = "plot",
+         plot.margin = unit(c(0, 2, 0, 0), "mm"))
> # Save the plot.
> ggsave(file.path(figures.folder, "location-effects.png"),
+     plot = location.plot,
+     units = "cm", width = fig.width, height = fig.height)
> 
> # Show the OLS correlation between D (mediator) and Y (outcome.)
> library(margins)
> health.reg <- lm(Y_health ~ 1 + any_healthcare + hh_size * lottery_iv +
+     dia_diagnosis + ast_diagnosis + hbp_diagnosis + emp_diagnosis +
+     ami_diagnosis + chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis,
+     data = analysis.data)
> print(summary(health.reg))

Call:
lm(formula = Y_health ~ 1 + any_healthcare + hh_size * lottery_iv + 
    dia_diagnosis + ast_diagnosis + hbp_diagnosis + emp_diagnosis + 
    ami_diagnosis + chf_diagnosis + dep_diagnosis + chl_diagnosis + 
    kid_diagnosis, data = analysis.data)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.8224 -0.4830  0.2131  0.3585  1.0735 

Coefficients:
                     Estimate Std. Error t value Pr(>|t|)    
(Intercept)          0.752618   0.011242  66.946  < 2e-16 ***
any_healthcare      -0.019013   0.010436  -1.822  0.06848 .  
hh_size2             0.014784   0.014307   1.033  0.30148    
hh_size3             0.247382   0.458140   0.540  0.58923    
lottery_iv           0.053327   0.010434   5.111 3.26e-07 ***
dia_diagnosis       -0.131021   0.014382  -9.110  < 2e-16 ***
ast_diagnosis       -0.035706   0.011530  -3.097  0.00196 ** 
hbp_diagnosis       -0.105119   0.010483 -10.027  < 2e-16 ***
emp_diagnosis       -0.237842   0.017037 -13.960  < 2e-16 ***
ami_diagnosis       -0.125752   0.019864  -6.331 2.53e-10 ***
chf_diagnosis       -0.047638   0.034086  -1.398  0.16227    
dep_diagnosis       -0.145484   0.009172 -15.861  < 2e-16 ***
chl_diagnosis       -0.055139   0.011201  -4.923 8.65e-07 ***
kid_diagnosis       -0.132490   0.018003  -7.359 1.98e-13 ***
hh_size2:lottery_iv  0.001658   0.019155   0.087  0.93103    
hh_size3:lottery_iv -0.262300   0.470731  -0.557  0.57739    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.458 on 11110 degrees of freedom
Multiple R-squared:  0.1286,	Adjusted R-squared:  0.1275 
F-statistic: 109.3 on 15 and 11110 DF,  p-value: < 2.2e-16

> happy.reg <- lm(Y_happy ~ 1 + any_healthcare + hh_size * lottery_iv +
+     dia_diagnosis + ast_diagnosis + hbp_diagnosis + emp_diagnosis +
+     ami_diagnosis + chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis,
+     data = analysis.data)
> print(summary(happy.reg))

Call:
lm(formula = Y_happy ~ 1 + any_healthcare + hh_size * lottery_iv + 
    dia_diagnosis + ast_diagnosis + hbp_diagnosis + emp_diagnosis + 
    ami_diagnosis + chf_diagnosis + dep_diagnosis + chl_diagnosis + 
    kid_diagnosis, data = analysis.data)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.8135 -0.5305  0.2251  0.3809  0.7655 

Coefficients:
                     Estimate Std. Error t value Pr(>|t|)    
(Intercept)          0.713501   0.011341  62.916  < 2e-16 ***
any_healthcare       0.032929   0.010527   3.128  0.00176 ** 
hh_size2             0.042203   0.014432   2.924  0.00346 ** 
hh_size3             0.286499   0.462153   0.620  0.53532    
lottery_iv           0.060298   0.010525   5.729 1.04e-08 ***
dia_diagnosis       -0.018118   0.014508  -1.249  0.21175    
ast_diagnosis        0.005612   0.011631   0.482  0.62948    
hbp_diagnosis       -0.048877   0.010575  -4.622 3.85e-06 ***
emp_diagnosis       -0.103435   0.017186  -6.019 1.82e-09 ***
ami_diagnosis       -0.089215   0.020038  -4.452 8.58e-06 ***
chf_diagnosis       -0.018079   0.034384  -0.526  0.59904    
dep_diagnosis       -0.193262   0.009253 -20.887  < 2e-16 ***
chl_diagnosis       -0.015988   0.011299  -1.415  0.15707    
kid_diagnosis       -0.090854   0.018161  -5.003 5.74e-07 ***
hh_size2:lottery_iv -0.041090   0.019323  -2.127  0.03348 *  
hh_size3:lottery_iv -0.455369   0.474854  -0.959  0.33760    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.462 on 11110 degrees of freedom
Multiple R-squared:  0.06946,	Adjusted R-squared:  0.0682 
F-statistic: 55.29 on 15 and 11110 DF,  p-value: < 2.2e-16

> # Show the IV effect between D (mediator) and Y (outcome.)
> library(fixest)
> health.iv <- feols(Y_health ~ 1 + hh_size * lottery_iv +
+     dia_diagnosis + ast_diagnosis + hbp_diagnosis + emp_diagnosis +
+     ami_diagnosis + chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis
+     | any_healthcare ~ factor(usual_health_location),
+     data = analysis.data)
> print(summary(health.iv))
TSLS estimation - Dep. Var.: Y_health
                  Endo.    : any_healthcare
                  Instr.   : factor(usual_health_location)
Second stage: Dep. Var.: Y_health
Observations: 11,126
Standard-errors: IID 
                     Estimate Std. Error    t value   Pr(>|t|)    
(Intercept)          0.526087   0.029070  18.096998  < 2.2e-16 ***
fit_any_healthcare   0.342041   0.043724   7.822745 5.6364e-15 ***
hh_size2             0.032837   0.015206   2.159439 3.0837e-02 *  
hh_size3             0.473913   0.482920   0.981349 3.2644e-01    
lottery_iv           0.032006   0.011263   2.841811 4.4940e-03 ** 
dia_diagnosis       -0.162337   0.015576 -10.422334  < 2.2e-16 ***
ast_diagnosis       -0.057017   0.012390  -4.602017 4.2305e-06 ***
hbp_diagnosis       -0.123528   0.011243 -10.987283  < 2.2e-16 ***
emp_diagnosis       -0.236896   0.017931 -13.211191  < 2.2e-16 ***
ami_diagnosis       -0.141216   0.020985  -6.729381 1.7877e-11 ***
chf_diagnosis       -0.067478   0.035950  -1.876981 6.0547e-02 .  
dep_diagnosis       -0.194653   0.011243 -17.312485  < 2.2e-16 ***
chl_diagnosis       -0.065744   0.011854  -5.546221 2.9859e-08 ***
kid_diagnosis       -0.151901   0.019084  -7.959496 1.8954e-15 ***
hh_size2:lottery_iv  0.009302   0.020180   0.460933 6.4486e-01    
hh_size3:lottery_iv -0.445092   0.495905  -0.897535 3.6945e-01    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.481698   Adj. R2: 0.03344
F-test (1st stage), any_healthcare: stat = 124.7, p < 2.2e-16, on 6 and 11,105 DoF.
                        Wu-Hausman: stat =  81.2, p < 2.2e-16, on 1 and 11,109 DoF.
                            Sargan: stat = 120.0, p < 2.2e-16, on 5 DoF.
> happy.iv <- feols(Y_happy ~ 1 + hh_size * lottery_iv +
+     dia_diagnosis + ast_diagnosis + hbp_diagnosis + emp_diagnosis +
+     ami_diagnosis + chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis
+     | any_healthcare ~ factor(usual_health_location),
+     data = analysis.data)
> print(summary(happy.iv))
TSLS estimation - Dep. Var.: Y_happy
                  Endo.    : any_healthcare
                  Instr.   : factor(usual_health_location)
Second stage: Dep. Var.: Y_happy
Observations: 11,126
Standard-errors: IID 
                     Estimate Std. Error   t value   Pr(>|t|)    
(Intercept)          0.437909   0.029966  14.61343  < 2.2e-16 ***
fit_any_healthcare   0.472179   0.045071  10.47628  < 2.2e-16 ***
hh_size2             0.064166   0.015675   4.09361 4.2772e-05 ***
hh_size3             0.562091   0.497801   1.12915 2.5886e-01    
lottery_iv           0.034359   0.011610   2.95953 3.0876e-03 ** 
dia_diagnosis       -0.056217   0.016056  -3.50134 4.6474e-04 ***
ast_diagnosis       -0.020315   0.012771  -1.59066 1.1171e-01    
hbp_diagnosis       -0.071274   0.011589  -6.14998 8.0159e-10 ***
emp_diagnosis       -0.102284   0.018484  -5.53365 3.2075e-08 ***
ami_diagnosis       -0.108029   0.021632  -4.99401 6.0037e-07 ***
chf_diagnosis       -0.042217   0.037058  -1.13920 2.5464e-01    
dep_diagnosis       -0.253080   0.011590 -21.83612  < 2.2e-16 ***
chl_diagnosis       -0.028891   0.012219  -2.36439 1.8077e-02 *  
kid_diagnosis       -0.114469   0.019672  -5.81879 6.0913e-09 ***
hh_size2:lottery_iv -0.031791   0.020802  -1.52823 1.2648e-01    
hh_size3:lottery_iv -0.677750   0.511186  -1.32584 1.8492e-01    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
RMSE: 0.496541   Adj. R2: -0.077821
F-test (1st stage), any_healthcare: stat = 124.7, p < 2.2e-16, on 6 and 11,105 DoF.
                        Wu-Hausman: stat = 118.5, p < 2.2e-16, on 1 and 11,109 DoF.
                            Sargan: stat =  99.7, p < 2.2e-16, on 5 DoF.
> 
> 
> ################################################################################
> ## Estimate the CM effects with my methods.
> 
> # State how many bootstrap replications are needed.
> boot.reps <- 10^3
> control.formula <- paste0("hh_size + dia_diagnosis +",
+     "ast_diagnosis + hbp_diagnosis + emp_diagnosis + ami_diagnosis +",
+     "chf_diagnosis + dep_diagnosis + chl_diagnosis + kid_diagnosis")
> 
> ## Panel A: Self-reported healthiness.
> # Naive selection-on-observables
> unadjusted.est <- mediate.selection(
+     Y = "Y_health", Z = "lottery_iv", D = "any_healthcare",
+     X_iv = "usual_health_location", X_minus = control.formula,
+     type = "unadjusted",
+     data = analysis.data,
+     boot.reps = boot.reps)
50 out of 1000, 5% done.
100 out of 1000, 10% done.
150 out of 1000, 15% done.
200 out of 1000, 20% done.
250 out of 1000, 25% done.
300 out of 1000, 30% done.
350 out of 1000, 35% done.
400 out of 1000, 40% done.
450 out of 1000, 45% done.
500 out of 1000, 50% done.
550 out of 1000, 55% done.
600 out of 1000, 60% done.
650 out of 1000, 65% done.
700 out of 1000, 70% done.
750 out of 1000, 75% done.
800 out of 1000, 80% done.
850 out of 1000, 85% done.
900 out of 1000, 90% done.
950 out of 1000, 95% done.
1000 out of 1000, 100% done.
There were 50 or more warnings (use warnings() to see the first 50)
> print(unadjusted.est)
Treatment, Mediator, Outcome: 
lottery_iv, any_healthcare, Y_health

unadjusted Estimates, With SEs from 1000 bootstrap replications.

                      Coefficients SE       
First-stage            4.139740     0.807011
ATE                    5.271893     0.844152
ADE                    5.373716     0.846739
AIE                   -0.080487     0.046014
Proportion, AIE / ATE -0.015267     0.009472
> # Parametric CF
> parametric.est <- mediate.selection(
+     Y = "Y_health", Z = "lottery_iv", D = "any_healthcare",
+     X_iv = "usual_health_location", X_minus = control.formula,
+     type = "parametric",
+     data = analysis.data,
+     boot.reps = boot.reps)
50 out of 1000, 5% done.
100 out of 1000, 10% done.
150 out of 1000, 15% done.
200 out of 1000, 20% done.
250 out of 1000, 25% done.
300 out of 1000, 30% done.
350 out of 1000, 35% done.
400 out of 1000, 40% done.
450 out of 1000, 45% done.
500 out of 1000, 50% done.
550 out of 1000, 55% done.
600 out of 1000, 60% done.
650 out of 1000, 65% done.
700 out of 1000, 70% done.
750 out of 1000, 75% done.

There were 50 or more warnings (use warnings() to see the first 50)
Execution halted
