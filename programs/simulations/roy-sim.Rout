
R version 4.3.3 (2024-02-29) -- "Angel Food Cake"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #!/usr/bin/R
> ## Senan Hogan-Hennessy, 16 Jan 2025
> ## Simulate the system for indirect + direct effects, with Roy selection.
> # Show the date:
> print(format(Sys.time(), "%H:%M %Z %A, %d %B %Y"))
[1] "18:15 EST Tuesday, 11 February 2025"
> 
> ## Load libraries
> # Functions for data manipulation and visualisation
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> # Library for better colour choice.
> library(ggthemes)
> # Library for equations in plots
> library(latex2exp)
> # Causal medation package, Imai Keele Yamamoto (2010)
> library(mediation)
Loading required package: MASS

Attaching package: ‘MASS’

The following object is masked from ‘package:dplyr’:

    select

Loading required package: Matrix

Attaching package: ‘Matrix’

The following objects are masked from ‘package:tidyr’:

    expand, pack, unpack

Loading required package: mvtnorm
Loading required package: sandwich
mediation: Causal Mediation Analysis
Version: 4.5.0

> # Package for classical selection estimators (i.e., MLE)
> library(sampleSelection)
Loading required package: maxLik
Loading required package: miscTools

Please cite the 'maxLik' package as:
Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.

If you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:
https://r-forge.r-project.org/projects/maxlik/
> # Package for more distributions to sample from.
> library(mvtnorm)
> library(MASS)
> # Package for semi-parametric regressor, splines by bs(.).
> library(splines)
> 
> ## Set up the R environment
> set.seed(47)
> # Define number of digits in tables and graphs
> digits.no <- 3
> # Define where output files go.
> output.folder <- file.path("sim-output")
> # Set the options for the plot sizes, in saving ggplot output.
> fig.height <- 10
> fig.width <- fig.height
> 
> # Define the sample size to work with.
> sample.N <- 10^4
> 
> 
> ################################################################################
> ## Define a function to simulate data in the triangular system.
> 
> # Define a function to simulate all observed + unobserved data 
> simulate.data <- function(rho, sigma_0, sigma_1, sigma_C,
+         sample.size = sample.N){
+     ### Inputs:
+     ## X, a matrix of covariates, continuous or binary values.
+     ## rho \in [-1, +1] measuring correlation between U_0, U_1.
+     ## sigma_0 >= 0 measuring standard deviation of U_0.
+     ## sigma_1 >= 0 measuring standard deviation of U_1.
+     ## sigma_C >= 0 measuring standard deviation of U_C.
+     ## sample.size: integer, representing output sample size (i.e., N).
+     # First covariate (\vec X_i^-)
+     X_minus <- 4 + rnorm(sample.size, mean = 0, sd = 1)
+     # Second covariate (instrument for the control function).
+     X_IV <- rbinom(sample.size, 1, 1 / 2)
+     # Simulate the unobserved error terms.
+     U_all <- mvrnorm(n = sample.size, mu = c(0, 0, 0),
+         Sigma = matrix(c(
+             sigma_0^2,               rho * sigma_0 * sigma_1, 0,
+             rho * sigma_0 * sigma_1, sigma_1^2,               0,
+             0,                       0,                       sigma_C^2),
+                 ncol = 3),
+         empirical = FALSE)
+     U_0 <- U_all[, 1]
+     U_1 <- U_all[, 2]
+     U_C <- U_all[, 3]
+     # Define the mean potential outcomes.
+     mu_outcome_z_d_X <- function(z, d, x_minus){
+         return(x_minus + (z + d + z * d))
+     }
+     mu_cost_z_X <- function(z, x_minus, x_iv){
+         return(- 3 * z + x_minus - x_iv)
+     }
+     # Y_i(Z, D) = mu_D(Z; X_i) + U_D
+     Y_0_0 <- mu_outcome_z_d_X(0, 0, X_minus) + U_0
+     Y_0_1 <- mu_outcome_z_d_X(0, 1, X_minus) + U_1
+     Y_1_0 <- mu_outcome_z_d_X(1, 0, X_minus) + U_0
+     Y_1_1 <- mu_outcome_z_d_X(1, 1, X_minus) + U_1
+     # D_i(Z)= 1{ Y(Z, 1) - Y(Z, 0) >= C_i }
+     D_0 <- as.integer(Y_0_1 - Y_0_0 >= mu_cost_z_X(0, X_minus, X_IV) + U_C)
+     D_1 <- as.integer(Y_1_1 - Y_1_0 >= mu_cost_z_X(1, X_minus, X_IV) + U_C)
+     # Generate the individual effects (direct + indirect)
+     probZ <- 0.5
+     Z <- rbinom(sample.size, 1, probZ)
+     # Observed outcomes: D, Y
+     D <- (Z * D_1) + ((1 - Z) * D_0)
+     # Generate the list of observed outcomes
+     Y <- (Z * D * Y_1_1) +
+         (Z * (1 - D) * Y_1_0) +
+         ((1 - Z) * D * Y_0_1) +
+         ((1 - Z) * (1 - D) * Y_0_0)
+     # Put these data to a coherent data frame.
+     combined.data <- data.frame(
+         # Observed data
+         Z, D, Y,  X_minus, X_IV,
+         # Unobserved, potential outcomes and compliance.
+         D_0, D_1,
+         Y_0_0, Y_0_1, Y_1_0, Y_1_1,
+         #mu0_Z0_X, mu1_Z0_X, mu0_Z1_X, mu1_Z1_X, muC_Z0_X, muC_Z1_X, 
+         U_0, U_1, U_C)
+     # Return the simulated data as a data frame.
+     return(combined.data)
+ }
> 
> 
> ################################################################################
> ## Define a function to show the theoretical values for the data.
> theoretical.values <- function(sim.data, digits.no = 3, print.truth = FALSE){
+     ### Inputs:
+     ## sim.data, a data frame simulated from above.
+     # Extract the potentials from simulated data.
+     Z <- sim.data$Z
+     D <- sim.data$D
+     Y <- sim.data$Y
+     X_minus <- sim.data$X_minus
+     X_IV <- sim.data$X_IV
+     D_0 <- sim.data$D_0
+     D_1 <- sim.data$D_1
+     Y_0_0 <- sim.data$Y_0_0
+     Y_0_1 <- sim.data$Y_0_1
+     Y_1_0 <- sim.data$Y_1_0
+     Y_1_1 <- sim.data$Y_1_1
+     U_0 <- sim.data$U_0
+     U_1 <- sim.data$U_1
+     U_C <- sim.data$U_C
+     # Get the true first-stage effects
+     first_stage <- D_1 - D_0
+     average_first_stage <- mean(first_stage)
+     # Get the theoretical total effect/reduced form/ITT
+     total_effect <-
+         (Y_1_1 - Y_0_0) * (D_1 == 1 & D_0 == 0) +
+         (Y_1_1 - Y_0_1) * (D_1 == 1 & D_0 == 1) +
+         (Y_1_0 - Y_0_0) * (D_1 == 0 & D_0 == 0)
+     average_total_effect <- mean(total_effect)
+     # Get the theoretical indirect effect.
+     indirect_effect <-
+         (Z * (Y_1_1 - Y_1_0) + (1 - Z) * (Y_0_1 - Y_0_0)) * (D_1 == 1 & D_0 == 0)
+     average_indirect_effect <- mean(indirect_effect)
+     # Get the theoretical direct effect.
+     direct_effect <- (D * (Y_1_1 - Y_0_1) + (1 - D) * (Y_1_0 - Y_0_0))
+         #(D * (Y_1_1 - Y_0_1) + (1 - D) * (Y_1_0 - Y_0_0)) * (D_1 == 1 & D_0 == 0) +
+         #(Y_1_1 - Y_0_1) * (D_1 == 1 & D_0 == 1) +
+         #(Y_1_0 - Y_0_0) * (D_1 == 0 & D_0 == 0)
+     average_direct_effect <- mean(direct_effect)
+     # Show the real underlying values.
+     if (print.truth == TRUE){
+         print("Here is a summary of the (unobserved) true effects:")
+         # Show how many ATs, NTs, Compliers in terms of D_i(Z) for Z = 0, 1.
+         print("How many mediator compliers in the system?")
+         print(table(D_1, D_0) / NROW(sim.data))
+         print("How many actually took the mediator, i.e. Pr(D = 1)?")
+         print(mean(D))
+         # Show the real treatment effects
+         print(paste0(c("The average total effect:",    as.numeric(average_total_effect))))
+         print(paste0(c("The average first-stage:",     as.numeric(average_first_stage))))
+         print(paste0(c("The average direct effect:",   as.numeric(average_direct_effect))))
+         print(paste0(c("The average indirect effect:", as.numeric(average_indirect_effect))))
+     
+     }
+     # Define a named list to return
+     output.list <- list(
+         average_first_stage     = average_first_stage,
+         average_total_effect    = average_total_effect,
+         average_direct_effect   = average_direct_effect,
+         average_indirect_effect = average_indirect_effect)
+     # Return the output.list
+     return(output.list)
+ }
> 
> ################################################################################
> ## Define a function to estimate mediation, given the first + second-stages.
> 
> # Estimate the values, given a first and second-stages
> estimated.values <- function(
+     firststage.reg, direct.reg, indirect.reg, example.data){
+     ### Inputs:
+     ## example.data, a data frame simulated from above.
+     # calculate the first-stage by prediction
+     firststage.est <- predict(
+         firststage.reg, newdata = mutate(example.data, Z = 1), type = "response") - predict(
+             firststage.reg, newdata = mutate(example.data, Z = 0), type = "response")
+     # calculate the second-stage direct effect
+     direct.est <- predict(
+         direct.reg, newdata = mutate(example.data, Z = 1)) -
+         predict(direct.reg, newdata = mutate(example.data, Z = 0))
+     # calculate the second-stage indirect effect
+     indirect.est <- predict(
+         indirect.reg, newdata = mutate(example.data, D = 1)) -
+         predict(indirect.reg, newdata = mutate(example.data, D = 0))
+     # Add on the K_0, K_1 conditional on D_i = 0, 1 respectively for compliers.
+     # # Estimate the kappa-weight
+     # hat_probZ <- lm(Z ~ 1 + X_IV * bs(X_minus, df = 10, intercept = TRUE),
+     #     data = example.data)$fitted
+     # kappa_1 <- example.data$D * ((example.data$Z - hat_probZ) / (
+     #     (1 - hat_probZ) * hat_probZ))
+     # kappa_0 <- (1 - example.data$D) * (((1 - example.data$Z) - (1 - hat_probZ)) / (
+     #     (1 - hat_probZ) * hat_probZ))
+     # kappa.weight <- kappa_1 * hat_probZ + kappa_0 * (1 - hat_probZ)
+     # # Calculate the term to add on.
+     # K_0 <- weighted.mean(predict(secondstage.reg, newdata = mutate(
+     #     example.data, Z = 0, D = 0, X_minus = 0)),
+     #     kappa.weight * (1 - example.data$D), na.rm = TRUE)
+     # K_1 <- weighted.mean(predict(secondstage.reg, newdata = mutate(
+     #     example.data, Z = 0, D = 0, X_minus = 0)),
+     #     kappa.weight * example.data$D, na.rm = TRUE)
+     # indirect.est <- indirect.est + (K_1 - K_0)
+     # Return the mean estimates.
+     output.list <- list(
+         "first-stage"     = mean(firststage.est, na.rm = TRUE),
+         "direct-effect"   = mean(direct.est, na.rm = TRUE),
+         "indirect-effect" = mean(firststage.est * indirect.est, na.rm = TRUE))
+     # Return the output.list
+     return(output.list)
+ }
> 
> # Define a function to cross-fit the semi-parametric control function.
> cf_crossfit_mediate <- function(example.data){
+     # 1. Calculate the split in half, two cross-fit samples
+     example.size <- NROW(example.data)
+     cross.index <- sample(seq(1, example.size),
+         size = 0.5 * example.size, replace = FALSE)
+     firstcross.data <- example.data[cross.index,]
+     secondcross.data <- example.data[-cross.index,]
+     # 2. calculate the CF model in the first cross sample.
+     firstcross_firststage.reg <- lm(D ~ (1 + Z) * X_IV *
+         bs(X_minus, df = 10, intercept = TRUE),
+         data = firstcross.data)
+     firstcross.data$K <- firstcross_firststage.reg$residuals
+     #TODO: remove the separated direct + indirect effects.
+     #firstcross_direct.reg <- lm(Y ~ (1 + Z * D) + X_minus +
+     #    bs(K, knots = seq(-1, 1, by = 0.05), intercept = FALSE),
+     #    data = firstcross.data)
+     firstcross.data$K_0 <- (1 - firstcross.data$D) * firstcross.data$K
+     firstcross.data$K_1 <- (firstcross.data$D) * firstcross.data$K
+     firstcross_indirect.reg <- lm(Y ~ (1 + Z * D) + X_minus +
+         bs(K_0, knots = seq(0, 1, by = 0.05), intercept = TRUE) +
+         bs(K_1, knots = seq(0, 1, by = 0.05), intercept = TRUE),
+         data = firstcross.data)
+     # 3. calculate the CF model on the second cross sample.
+     secondcross_firststage.reg <- lm(D ~ (1 + Z) * X_IV *
+         bs(X_minus, df = 10, intercept = TRUE),
+         data = secondcross.data)
+     secondcross.data$K <- secondcross_firststage.reg$residuals
+     #secondcross_direct.reg <- lm(
+     #    Y ~ (1 + Z * D) + X_minus +
+     #    bs(K, knots = seq(-1, 1, by = 0.05), intercept = FALSE),
+     #    data = secondcross.data)
+     secondcross.data$K_0 <- (1 - secondcross.data$D) * secondcross.data$K
+     secondcross.data$K_1 <- (secondcross.data$D) * secondcross.data$K
+     secondcross_indirect.reg <- lm(
+         Y ~ (1 + Z * D) + X_minus +
+         bs(K_0, knots = seq(0, 1, by = 0.05), intercept = FALSE) +
+         bs(K_1, knots = seq(0, 1, by = 0.05), intercept = FALSE),
+         data = secondcross.data)
+     # 4. Predict the estimate on the opposite data.
+     firstcross.est <- estimated.values(firstcross_firststage.reg,
+         firstcross_indirect.reg, firstcross_indirect.reg, secondcross.data)
+     secondcross.est <- estimated.values(secondcross_firststage.reg,
+         secondcross_indirect.reg, secondcross_indirect.reg, firstcross.data)
+     # Resturn the averaged estimates.
+     output.list <- list(
+         "first-stage"     = mean(c(
+             firstcross.est$`first-stage`, secondcross.est$`first-stage`), na.rm = FALSE),
+         "direct-effect"   = mean(c(
+             firstcross.est$`direct-effect`, secondcross.est$`direct-effect`), na.rm = FALSE),
+         "indirect-effect" = mean(c(
+             firstcross.est$`indirect-effect`, secondcross.est$`indirect-effect`), na.rm = FALSE))
+     # Return the output.list
+     return(output.list)
+ }
> 
> # Bootstrap the estimates.
> estimated.loop <- function(boot.reps, example.data, bootstrap = TRUE){
+     # Define lists the will be returned:
+     # 2. Naive OLS.
+     ols_direct_effect <- c()
+     ols_indirect_effect <- c()
+     # 3. Control function.
+     cf_direct_effect <- c()
+     cf_indirect_effect <- c()
+     # More in the future ....
+     ## Loop across the bootstraps values.
+     for (i in seq(1, boot.reps)){
+         # If bootstrapping, just resample from provided data.
+         if (bootstrap == TRUE) {
+             boot.indicies <- sample(
+                 seq(1, NROW(example.data)), NROW(example.data), replace = TRUE)
+             boot.data <- example.data[boot.indicies, ]
+         }
+         # If a regular re-simulation, get new data.
+         else if (bootstrap == FALSE){
+             boot.data <- simulate.data(0.5, 1, 2, 0.5)
+             if ((100 * (i / boot.reps)) %% 1 == 0) {
+                 print(paste0(i, " out of ", boot.reps, ", ", 100 * (i / boot.reps), "% done."))
+             }
+         }
+         else {stop("The `bootstrap' option only takes values of TRUE or FALSE.")}
+         # Calculate the truth values, given the simulated data
+         truth.est <- theoretical.values(example.data)
+         # Now get the mediation effects, by different approaches.
+         # 2. OLS estimate of second-stage
+         ols_firststage.reg <- lm(D ~ (1 + Z) + X_minus + X_IV, data = boot.data)
+         ols_secondstage.reg <- lm(Y ~ 1 + Z * D + X_minus, data = boot.data)
+         ols.est <- estimated.values(ols_firststage.reg,
+             ols_secondstage.reg, ols_secondstage.reg, boot.data)
+         # 3. Control Function estimates.
+         cf.est <- cf_crossfit_mediate(boot.data)
+         # Save the outputs.
+         ols_direct_effect[i]   <- ols.est$`direct-effect`
+         ols_indirect_effect[i] <- ols.est$`indirect-effect`
+         cf_direct_effect[i]    <- cf.est$`direct-effect`
+         cf_indirect_effect[i]  <- cf.est$`indirect-effect`
+     }
+     # Return the bootstrap data.
+     output.list <- list()
+     output.list$data <- data.frame(
+         truth_direct_effect   = as.numeric(truth.est$average_direct_effect),
+         ols_direct_effect     = ols_direct_effect,
+         cf_direct_effect      = cf_direct_effect,
+         truth_indirect_effect = as.numeric(truth.est$average_indirect_effect),
+         ols_indirect_effect   = ols_indirect_effect,
+         cf_indirect_effect    = cf_indirect_effect
+     )
+     # Calculate the needed statistics, to return
+     output.list$estimates <- data.frame(
+         # Truth
+         truth_direct_effect     = as.numeric(truth.est$average_direct_effect),
+         truth_indirect_effect   = as.numeric(truth.est$average_indirect_effect),
+         # OLS mean, and the 95% confidence intervals
+         ols_direct_effect       = as.numeric(mean(ols_direct_effect)),
+         ols_direct_effect_se    = as.numeric(sd(ols_direct_effect)),
+         ols_direct_effect_up    = as.numeric(quantile(ols_direct_effect,
+             probs = 0.975, na.rm = TRUE)),
+         ols_direct_effect_low   = as.numeric(quantile(ols_direct_effect,
+             probs = 0.025, na.rm = TRUE)),
+         ols_indirect_effect     = as.numeric(mean(ols_indirect_effect)),
+         ols_indirect_effect_se  = as.numeric(sd(ols_indirect_effect)),
+         ols_indirect_effect_up  = as.numeric(quantile(ols_indirect_effect,
+             probs = 0.975, na.rm = TRUE)),
+         ols_indirect_effect_low = as.numeric(quantile(ols_indirect_effect,
+             probs = 0.025, na.rm = TRUE)),
+         # Control Fun mean, and the 95% confidence intervals
+         cf_direct_effect        = as.numeric(mean(cf_direct_effect)),
+         cf_direct_effect_se     = as.numeric(sd(cf_direct_effect)),
+         cf_direct_effect_up     = as.numeric(quantile(cf_direct_effect,
+             probs = 0.975, na.rm = TRUE)),
+         cf_direct_effect_low    = as.numeric(quantile(cf_direct_effect,
+             probs = 0.025, na.rm = TRUE)),
+         cf_indirect_effect      = as.numeric(mean(cf_indirect_effect)),
+         cf_indirect_effect_se   = as.numeric(sd(cf_indirect_effect)),
+         cf_indirect_effect_up   = as.numeric(quantile(cf_indirect_effect,
+             probs = 0.975, na.rm = TRUE)),
+         cf_indirect_effect_low  = as.numeric(quantile(cf_indirect_effect,
+             probs = 0.025, na.rm = TRUE))
+     )
+     return(output.list)
+ }
> 
> 
> ################################################################################
> ## Compare estimation methods, in one simulation.
> 
> ## Simulate the data: rho, sigma_0, sigma_1, sigma_C = 0.5, 1, 2, 0.5
> simulated.data <- simulate.data(0.5, 1, 2, 0.5)
> # SHow the theoretical direct + indirect values
> print(theoretical.values(simulated.data, print.truth = TRUE))
[1] "Here is a summary of the (unobserved) true effects:"
[1] "How many mediator compliers in the system?"
   D_0
D_1      0      1
  0 0.2350 0.0000
  1 0.6402 0.1248
[1] "How many actually took the mediator, i.e. Pr(D = 1)?"
[1] 0.4371
[1] "The average total effect:" "2.55334435389143"         
[1] "The average first-stage:" "0.6402"                  
[1] "The average direct effect:" "1.4371"                    
[1] "The average indirect effect:" "1.10064435389143"            
$average_first_stage
[1] 0.6402

$average_total_effect
[1] 2.553344

$average_direct_effect
[1] 1.4371

$average_indirect_effect
[1] 1.100644

> 
> # Show that the regression specification holds exactly (after debiasing outcome).
> true_firststage.reg <- glm(D ~ (1 + Z) + X_IV + X_minus +
+     U_C, #U_0 + U_1,
+     family = binomial(link = "probit"),
+     data = simulated.data)
> true_secondstage.reg <- lm(Y ~ (1 + Z * D) + X_minus +
+     # including the unobserved errors:
+     U_0 + (D * U_0) + (D * U_1),
+     data = simulated.data)
> print(theoretical.values(simulated.data))
$average_first_stage
[1] 0.6402

$average_total_effect
[1] 2.553344

$average_direct_effect
[1] 1.4371

$average_indirect_effect
[1] 1.100644

> print(estimated.values(true_firststage.reg,
+     true_secondstage.reg, true_secondstage.reg, simulated.data))
$`first-stage`
[1] 0.6433954

$`direct-effect`
[1] 1.4371

$`indirect-effect`
[1] 0.976029

> # See how the first and second-stages are perfect:
> print(summary(true_firststage.reg))

Call:
glm(formula = D ~ (1 + Z) + X_IV + X_minus + U_C, family = binomial(link = "probit"), 
    data = simulated.data)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  0.65435    0.07083   9.239   <2e-16 ***
Z            2.34169    0.03838  61.014   <2e-16 ***
X_IV         0.50159    0.03382  14.830   <2e-16 ***
X_minus     -0.59227    0.01866 -31.745   <2e-16 ***
U_C         -0.66745    0.03457 -19.306   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 13704  on 9999  degrees of freedom
Residual deviance:  7373  on 9995  degrees of freedom
AIC: 7383

Number of Fisher Scoring iterations: 5

> print(summary(true_secondstage.reg))

Call:
lm(formula = Y ~ (1 + Z * D) + X_minus + U_0 + (D * U_0) + (D * 
    U_1), data = simulated.data)

Residuals:
       Min         1Q     Median         3Q        Max 
-7.328e-13 -2.400e-15 -9.000e-16  3.000e-16  8.007e-12 

Coefficients:
              Estimate Std. Error    t value Pr(>|t|)    
(Intercept)  1.030e-13  3.950e-15  2.608e+01   <2e-16 ***
Z            1.000e+00  3.066e-15  3.262e+14   <2e-16 ***
D            1.000e+00  4.428e-15  2.258e+14   <2e-16 ***
X_minus      1.000e+00  9.005e-16  1.111e+15   <2e-16 ***
U_0          1.000e+00  1.368e-15  7.313e+14   <2e-16 ***
U_1          4.823e-16  7.801e-16  6.180e-01    0.536    
Z:D          1.000e+00  5.035e-15  1.986e+14   <2e-16 ***
D:U_0       -1.000e+00  2.062e-15 -4.848e+14   <2e-16 ***
D:U_1        1.000e+00  1.190e-15  8.404e+14   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 8.445e-14 on 9991 degrees of freedom
Multiple R-squared:      1,	Adjusted R-squared:      1 
F-statistic: 9.367e+29 on 8 and 9991 DF,  p-value: < 2.2e-16

> 
> # Show how the OLS result gives a bias result (if rho != 0),
> # using the same second-stage for both direct + indirect estimates.
> ols_firststage.reg <- lm(D ~ (1 + Z) + X_minus + X_IV, data = simulated.data)
> ols_secondstage.reg <- lm(Y ~ 1 + Z * D + X_minus, data = simulated.data)
> print(theoretical.values(simulated.data))
$average_first_stage
[1] 0.6402

$average_total_effect
[1] 2.553344

$average_direct_effect
[1] 1.4371

$average_indirect_effect
[1] 1.100644

> print(estimated.values(ols_firststage.reg,
+     ols_secondstage.reg, ols_secondstage.reg, simulated.data))
$`first-stage`
[1] 0.6430122

$`direct-effect`
[1] 0.5218927

$`indirect-effect`
[1] 2.044705

> 
> # Show how (unknown) control function gets it correct, in 2 steps (with splines)
> cf_firststage.reg <- lm(D ~ (1 + Z) * X_IV  *
+     bs(X_minus, df = 10, intercept = TRUE),
+     data = simulated.data)
> # Direct estimate.
> simulated.data$K <- cf_firststage.reg$residuals
> cf_direct.reg <- lm(Y ~ (1 + Z * D) + X_minus +
+     bs(K, knots = seq(-1, 1, by = 0.05), intercept = FALSE),
+     data = simulated.data)
> # Indirect estimate.
> simulated.data$K_0 <- (1 - simulated.data$D) * simulated.data$K
> simulated.data$K_1 <- (simulated.data$D) * simulated.data$K
> cf_indirect.reg <- lm(Y ~ (1 + Z * D) + X_minus +
+     bs(K_0, knots = seq(0, 1, by = 0.05), intercept = TRUE) +
+     bs(K_1, knots = seq(0, 1, by = 0.05), intercept = TRUE),
+     data = simulated.data)
> print(theoretical.values(simulated.data))
$average_first_stage
[1] 0.6402

$average_total_effect
[1] 2.553344

$average_direct_effect
[1] 1.4371

$average_indirect_effect
[1] 1.100644

> print(estimated.values(cf_firststage.reg,
+     cf_direct.reg, cf_indirect.reg, simulated.data))
$`first-stage`
[1] 0.6430719

$`direct-effect`
[1] 1.500423

$`indirect-effect`
[1] 0.6646005

> # Cross-fit the CF approach to avoid over-fitting bias in the semi-para step.
> print(theoretical.values(simulated.data))
$average_first_stage
[1] 0.6402

$average_total_effect
[1] 2.553344

$average_direct_effect
[1] 1.4371

$average_indirect_effect
[1] 1.100644

> print(cf_crossfit_mediate(simulated.data))
$`first-stage`
[1] 0.6429099

$`direct-effect`
[1] 1.477412

$`indirect-effect`
[1] 1.186802

There were 26 warnings (use warnings() to see them)
> 
> #! Test: Imbens Newey (2009) conditional CDF as the control function.
> cf_firststage.reg <- lm(D ~ (1 + Z) * X_IV *
+     bs(X_minus, df = 20, intercept = TRUE),
+     data = simulated.data)
> control.fun <- ecdf(cf_firststage.reg$fitted)
> simulated.data$K <- as.numeric(control.fun(cf_firststage.reg$fitted))
> cdf_direct.reg <- lm(Y ~ (1 + Z * D) + X_minus +
+     bs(K, knots = seq(0, 1, by = 0.05), intercept = TRUE),
+     data = simulated.data)
> simulated.data$K_0 <- (1 - simulated.data$D) * (1 - simulated.data$K)
> simulated.data$K_1 <- simulated.data$D * simulated.data$K
> cdf_indirect.reg <- lm(Y ~ (1 + Z * D) + X_minus +
+     bs(K_0, knots = seq(0, 1, by = 0.05), intercept = TRUE)+
+     bs(K_1, knots = seq(0, 1, by = 0.05), intercept = TRUE),
+     data = simulated.data)
> print(theoretical.values(simulated.data))
$average_first_stage
[1] 0.6402

$average_total_effect
[1] 2.553344

$average_direct_effect
[1] 1.4371

$average_indirect_effect
[1] 1.100644

> print(estimated.values(cf_firststage.reg,
+     cdf_direct.reg, cdf_indirect.reg, simulated.data))
$`first-stage`
[1] 0.6429651

$`direct-effect`
[1] 1.402076

$`indirect-effect`
[1] 142.6615

> 
> #! Test, add on the K_0 and K_1 conditional on D_i = 0,1 respectively in truth
> firststage.est <- predict(
+     true_firststage.reg, newdata = mutate(simulated.data, Z = 1), type = "response") - predict(
+         true_firststage.reg, newdata = mutate(simulated.data, Z = 0), type = "response")
> # calculate the second-stage indirect effect
> indirect.est <- predict(
+     true_secondstage.reg, newdata = mutate(simulated.data, D = 1)) -
+     predict(true_secondstage.reg, newdata = mutate(simulated.data, D = 0))
> add.term <- weighted.mean(simulated.data$U_1 - simulated.data$U_0,
+     simulated.data$D_0 == 0 & simulated.data$D_1 == 1)
> mean(firststage.est * (indirect.est + add.term))
[1] 1.124913
> print(theoretical.values(simulated.data)$average_indirect_effect)
[1] 1.100644
> 
> #! Do the same thing, but kappa weighted to the compliers inside the CF estimate.
> # Estimate the kappa-weight.
> hat_probZ <- lm(Z ~ 1 * X_IV * bs(X_minus, df = 10, intercept = TRUE),
+     data = simulated.data)$fitted
> kappa_1 <- simulated.data$D * ((simulated.data$Z - hat_probZ) / (
+     (1 - hat_probZ) * hat_probZ))
> kappa_0 <- (1 - simulated.data$D) * (((1 - simulated.data$Z) - (1 - hat_probZ)) / (
+     (1 - hat_probZ) * hat_probZ))
> kappa.weight <- kappa_1 * hat_probZ + kappa_0 * (1 - hat_probZ)
> # Calculate the term to add on.
> errors <- predict(cdf_direct.reg, newdata = mutate(simulated.data,
+     Z = 0, D = 0, X_minus = 0))
> add.term <- weighted.mean(errors, simulated.data$D * kappa.weight) -
+     weighted.mean(errors, (1 - simulated.data$D) * kappa.weight)
> add.term <- weighted.mean(simulated.data$D * errors -
+     (1 - simulated.data$D) * errors, kappa.weight)
> mean(firststage.est * (indirect.est + add.term))
[1] 0.5193526
> 
> 
> ################################################################################
> ## Plot bootstrap results for one DGP, repeatedly drawn
> 
> # Base data to test out.
> simulated.data <- simulate.data(0.5, 1, 2, 0.5)
> 
> # Get bootstrapped point est for the CF approach
> sim.reps <- 10^2
> sim.est <- estimated.loop(sim.reps, simulated.data, bootstrap = FALSE)
[1] "1 out of 100, 1% done."
[1] "2 out of 100, 2% done."
[1] "3 out of 100, 3% done."
[1] "4 out of 100, 4% done."
[1] "5 out of 100, 5% done."
[1] "6 out of 100, 6% done."
[1] "8 out of 100, 8% done."
[1] "9 out of 100, 9% done."
[1] "10 out of 100, 10% done."
[1] "11 out of 100, 11% done."
[1] "12 out of 100, 12% done."
[1] "13 out of 100, 13% done."
[1] "15 out of 100, 15% done."
[1] "16 out of 100, 16% done."
[1] "17 out of 100, 17% done."
[1] "18 out of 100, 18% done."
[1] "19 out of 100, 19% done."
[1] "20 out of 100, 20% done."
[1] "21 out of 100, 21% done."
[1] "22 out of 100, 22% done."
[1] "23 out of 100, 23% done."
[1] "24 out of 100, 24% done."
[1] "25 out of 100, 25% done."
[1] "26 out of 100, 26% done."
[1] "27 out of 100, 27% done."
[1] "30 out of 100, 30% done."
[1] "31 out of 100, 31% done."
[1] "32 out of 100, 32% done."
[1] "33 out of 100, 33% done."
[1] "34 out of 100, 34% done."
[1] "35 out of 100, 35% done."
[1] "36 out of 100, 36% done."
[1] "37 out of 100, 37% done."
[1] "38 out of 100, 38% done."
[1] "39 out of 100, 39% done."
[1] "40 out of 100, 40% done."
[1] "41 out of 100, 41% done."
[1] "42 out of 100, 42% done."
[1] "43 out of 100, 43% done."
[1] "44 out of 100, 44% done."
[1] "45 out of 100, 45% done."
[1] "46 out of 100, 46% done."
[1] "47 out of 100, 47% done."
[1] "48 out of 100, 48% done."
[1] "49 out of 100, 49% done."
[1] "50 out of 100, 50% done."
[1] "51 out of 100, 51% done."
[1] "52 out of 100, 52% done."
[1] "53 out of 100, 53% done."
[1] "54 out of 100, 54% done."
[1] "59 out of 100, 59% done."
[1] "60 out of 100, 60% done."
[1] "61 out of 100, 61% done."
[1] "62 out of 100, 62% done."
[1] "63 out of 100, 63% done."
[1] "64 out of 100, 64% done."
[1] "65 out of 100, 65% done."
[1] "66 out of 100, 66% done."
[1] "67 out of 100, 67% done."
[1] "68 out of 100, 68% done."
[1] "69 out of 100, 69% done."
[1] "70 out of 100, 70% done."
[1] "71 out of 100, 71% done."
[1] "72 out of 100, 72% done."
[1] "73 out of 100, 73% done."
[1] "74 out of 100, 74% done."
[1] "75 out of 100, 75% done."
[1] "76 out of 100, 76% done."
[1] "77 out of 100, 77% done."
[1] "78 out of 100, 78% done."
[1] "79 out of 100, 79% done."
[1] "80 out of 100, 80% done."
[1] "81 out of 100, 81% done."
[1] "82 out of 100, 82% done."
[1] "83 out of 100, 83% done."
[1] "84 out of 100, 84% done."
[1] "85 out of 100, 85% done."
[1] "86 out of 100, 86% done."
[1] "87 out of 100, 87% done."
[1] "88 out of 100, 88% done."
[1] "89 out of 100, 89% done."
[1] "90 out of 100, 90% done."
[1] "91 out of 100, 91% done."
[1] "92 out of 100, 92% done."
[1] "93 out of 100, 93% done."
[1] "94 out of 100, 94% done."
[1] "95 out of 100, 95% done."
[1] "96 out of 100, 96% done."
[1] "97 out of 100, 97% done."
[1] "98 out of 100, 98% done."
[1] "99 out of 100, 99% done."
[1] "100 out of 100, 100% done."
There were 50 or more warnings (use warnings() to see the first 50)
> sim.data <- sim.est$data
> 
> ## Save the repated DGPs' point estimates as separate data.
> sim.data %>% write_csv(file.path(output.folder, "boot-sim-data.csv"))
> 
> 
> ################################################################################
> ## Compare estimation methods, across different sigma values.
> 
> # Define an empty dataframe, to start adding to.
> boot.values <- estimated.loop(1, simulated.data)$estimates
There were 18 warnings (use warnings() to see them)
> boot.values$sigma <- NA
> sigma.data <- boot.values[0, ]
> # Define values in rho \in [-1, 1] to go across
> sigma.values <- seq(0, 2, by = 0.25)
> # Define the number of boot reps for each
> boot.reps <- 10^2
> i <- 0
> 
> # Start the sigma loop
> for (sigma in sigma.values){
+     # Simulate the data: rho, sigma_0, sigma_1, sigma_C
+     sigma_sim.data <- simulate.data(0.5, sigma, 2 * sigma, 0.5)
+     # Get the truth + estimates + bootstrapped SEs, and save rho value
+     sigma.boot <- estimated.loop(boot.reps, sigma_sim.data,
+         bootstrap = TRUE)$estimates
+     sigma.boot$sigma <- sigma
+     # Add to the dataframe.
+     i <- i + 1
+     sigma.data[i, ] <- sigma.boot
+     # SHow far we are.
+     print(paste0(sigma, " in [0, 2], ", 100 * i / length(sigma.values), "% done."))
+     gc()
+ }
[1] "0 in [0, 2], 11.1111111111111% done."
[1] "0.25 in [0, 2], 22.2222222222222% done."
[1] "0.5 in [0, 2], 33.3333333333333% done."
[1] "0.75 in [0, 2], 44.4444444444444% done."
[1] "1 in [0, 2], 55.5555555555556% done."
[1] "1.25 in [0, 2], 66.6666666666667% done."
[1] "1.5 in [0, 2], 77.7777777777778% done."
[1] "1.75 in [0, 2], 88.8888888888889% done."
[1] "2 in [0, 2], 100% done."
There were 50 or more warnings (use warnings() to see the first 50)
> # Save the output data.
> sigma.data %>% write_csv(file.path(output.folder, "sigma-sim-data.csv"))
> 
> 
> ################################################################################
> ## Compare estimation methods, across different sigma values.
> 
> # Define an empty dataframe, to start adding to.
> boot.values <- estimated.loop(1, simulated.data)$estimates
There were 16 warnings (use warnings() to see them)
> boot.values$sigma_1 <- NA
> sigma_1.data <- boot.values[0, ]
> # Define values in rho \in [-1, 1] to go across
> sigma_1.values <- seq(0, 2, by = 0.25)
> # Define the number of boot reps for each
> boot.reps <- 10^2
> i <- 0
> 
> # Start the sigma_1 loop
> for (sigma_1 in sigma_1.values){
+     i <- i + 1
+     # Simulate the data: rho, sigma_0, sigma_1, sigma_C
+     sigma_1_sim.data <- simulate.data(0.5, 1, sigma_1, 0.5)
+     # Get the truth + estimates + bootstrapped SEs, and save rho value
+     sigma_1.boot <- estimated.loop(boot.reps, sigma_1_sim.data,
+         bootstrap = TRUE)$estimates
+     sigma_1.boot$sigma_1 <- sigma_1
+     # Add to the dataframe.
+     sigma_1.data[i, ] <- sigma_1.boot
+     # SHow far we are.
+     print(paste0(sigma_1, " in [0, 2], ", 100 * i / length(sigma_1.values), "% done."))
+     gc()
+ }
[1] "0 in [0, 2], 11.1111111111111% done."
[1] "0.25 in [0, 2], 22.2222222222222% done."
[1] "0.5 in [0, 2], 33.3333333333333% done."
[1] "0.75 in [0, 2], 44.4444444444444% done."
[1] "1 in [0, 2], 55.5555555555556% done."
[1] "1.25 in [0, 2], 66.6666666666667% done."
[1] "1.5 in [0, 2], 77.7777777777778% done."
[1] "1.75 in [0, 2], 88.8888888888889% done."
[1] "2 in [0, 2], 100% done."
There were 50 or more warnings (use warnings() to see the first 50)
> # Save the output data.
> sigma_1.data %>% write_csv(file.path(output.folder, "sigma-1-sim-data.csv"))
> 
> 
> ################################################################################
> ## Compare estimation methods, across different rho values.
> 
> # Define an empty dataframe, to start adding to.
> boot.values <- estimated.loop(1, simulated.data)$estimates
There were 18 warnings (use warnings() to see them)
> boot.values$rho <- NA
> rho.data <- boot.values[0, ]
> print(rho.data)
 [1] truth_direct_effect     truth_indirect_effect   ols_direct_effect      
 [4] ols_direct_effect_se    ols_direct_effect_up    ols_direct_effect_low  
 [7] ols_indirect_effect     ols_indirect_effect_se  ols_indirect_effect_up 
[10] ols_indirect_effect_low cf_direct_effect        cf_direct_effect_se    
[13] cf_direct_effect_up     cf_direct_effect_low    cf_indirect_effect     
[16] cf_indirect_effect_se   cf_indirect_effect_up   cf_indirect_effect_low 
[19] rho                    
<0 rows> (or 0-length row.names)
> # Define values in rho \in [-1, 1] to go across
> rho.values <- seq(-1, 1, by = 0.25)
> # Define the number of boot reps for each
> boot.reps <- 10^2
> i <- 0
> 
> # Start the rho loop
> for (rho in rho.values){
+     i <- i + 1
+     # Simulate the data: rho, sigma_0, sigma_1, sigma_C
+     rho_sim.data <- simulate.data(rho, 1, 2, 0.5)
+     # Get the truth + estimates + bootstrapped SEs, and save rho value
+     rho.boot  <- estimated.loop(boot.reps, rho_sim.data,
+         bootstrap = TRUE)$estimates
+     rho.boot$rho <- rho
+     # Add to the dataframe.
+     rho.data[i, ] <- rho.boot
+     # Show how far we 
+     print(paste0(rho, " in [-1, 1], ", 100 * i / length(rho.values), "% done."))
+     gc()
+ }
[1] "-1 in [-1, 1], 11.1111111111111% done."
[1] "-0.75 in [-1, 1], 22.2222222222222% done."
[1] "-0.5 in [-1, 1], 33.3333333333333% done."
[1] "-0.25 in [-1, 1], 44.4444444444444% done."
[1] "0 in [-1, 1], 55.5555555555556% done."
[1] "0.25 in [-1, 1], 66.6666666666667% done."
[1] "0.5 in [-1, 1], 77.7777777777778% done."
[1] "0.75 in [-1, 1], 88.8888888888889% done."
[1] "1 in [-1, 1], 100% done."
There were 50 or more warnings (use warnings() to see the first 50)
> 
> ## Save the output data.
> rho.data %>% write_csv(file.path(output.folder, "rho-sim-data.csv"))
> 
> proc.time()
    user   system  elapsed 
2383.532    9.646 2415.492 
